Since the project My-Sports itself is not a traditional Data Science project, we had to improvise quite a bit.
While our help with structuring the Database in the backend was imperative, there were no real usage data for us
to handle. As the app/website how we envisioned it would be set up from scratch with no real users or other
(external) datasets we decided to set up a fake user-database ourselves. Based on this we then began to also write
a python code for imaginary events having the ultimate goal in mind to have some sort of matching algorithm to match
users with the type of (sports)events that would be interesting for them.

Having this goal in mind we based our user database on the "personas" as defined by our fellow UX students.
The basis for the user_gen.py is a Dataframe which incapsulates all the criteria or filters as defined during our
sessions. Setting up a Dataframe structure with variables helped us adapt quickly to the upcoming new filters.
The variables initially set up as lists could then be coded according to our needs with the advantage of being able
to quickly adapt to changes being made by the group. In some cases we already progressed and further developed the
filters that may be integrated in the future, e.g. height and weight distributions that are quite important
for certain type of sports. Having this flexible structure helped having this freedom.
Additionally, to guarantee even more flexibility concerning the data generated, there is a line of code right from the
start that permits to type in the number of fake users the script has to generate.
The individual lists of variables like personal data, location and skills in the sports proposed within the app
are then combined within a final Dataframe. This Dataframe which is automatically exported in csv and json for ease
of usage in the backend would then serve as basis for the event_gen.py script.

Given the csv-file generated by the user_gen script the event_gen would then read the csv with pandas read_csv funtion
and serve as basis for the fake events. As the event_gen is closely correlated to the user_gen dataframe we then
proceeded with the type of filters related to the sports/event section. Having common datapoints within the two data
frames the initial set up was closely aligned. The output of the event_gen.py script does integrate a lot of features
as envisioned by the group. It groups users from the user_gen within events, has a designated host, a sport and time
and many other features just like a real event created.
The unified dataframe is finally exported in csv and json format.Since the project My-Sports itself is not a traditional Data Science project, we had to improvise quite a bit.
While our help with structuring the Database in the backend was imperative, there were no real usage data for us
to handle. As the app/website how we envisioned it would be set up from scratch with no real users or other
(external) datasets we decided to set up a fake user-database ourselves. Based on this we then began to also write
a python code for imaginary events having the ultimate goal in mind to have some sort of matching algorithm to match
users with the type of (sports)events that would be interesting for them.

Having this goal in mind we based our user database on the "personas" as defined by our fellow UX students.
The basis for the user_gen.py is a Dataframe which incapsulates all the criteria or filters as defined during our
sessions. Setting up a Dataframe structure with variables helped us adapt quickly to the upcoming new filters.
The variables initially set up as lists could then be coded according to our needs with the advantage of being able
to quickly adapt to changes being made by the group. In some cases we already progressed and further developed the
filters that may be integrated in the future, e.g. height and weight distributions that are quite important
for certain type of sports. Having this flexible structure helped having this freedom.
Additionally, to guarantee even more flexibility concerning the data generated, there is a line of code right from the
start that permits to type in the number of fake users the script has to generate.
The individual lists of variables like personal data, location and skills in the sports proposed within the app
are then combined within a final Dataframe. This Dataframe which is automatically exported in csv and json for ease
of usage in the backend would then serve as basis for the event_gen.py script.

Given the csv-file generated by the user_gen script the event_gen would then read the csv with pandas read_csv funtion
and serve as basis for the fake events. As the event_gen is closely correlated to the user_gen dataframe we then
proceeded with the type of filters related to the sports/event section. Having common datapoints within the two data
frames the initial set up was closely aligned. The output of the event_gen.py script does integrate a lot of features
as envisioned by the group. It groups users from the user_gen within events, has a designated host, a sport and time
and many other features just like a real event created.
The unified dataframe is finally exported in csv and json format.

The script df.py in this folder generate randomly a number defined by user of fake user for the website.

The generated users are exported in a csv and a json files in the same folder.
